{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.data-blogger.com/2016/01/20/spam-detection/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk import word_tokenize, NaiveBayesClassifier\n",
    "from nltk import classify\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import random\n",
    "import os, glob, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(text):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    features = {}\n",
    "    if \"!\" in text:\n",
    "        features[\"!\"] = True\n",
    "    if \"$\" in text:\n",
    "        features[\"$\"] = True\n",
    "        \n",
    "    lowercase = list('abcdefghijklmnopqrstuvwxyz')\n",
    "    uppercase = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "    \n",
    "    num_lowercase = 0\n",
    "    num_uppercase = 0\n",
    "    \n",
    "    for char in text:\n",
    "        if char in lowercase:\n",
    "            num_lowercase += 1\n",
    "        elif char in uppercase:\n",
    "            num_uppercase += 1\n",
    "    features[\"upper_ratio\"] = num_uppercase / (num_lowercase + num_uppercase)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamtexts = []\n",
    "spamtexts = []\n",
    "\n",
    "for filename in glob.glob('/Users/migmikael/Downloads/enron2/ham/*.txt'):\n",
    "    fin = open(filename, \"r\",encoding='utf-8', errors='ignore')\n",
    "    hamtexts.append(fin.read())\n",
    "    fin.close()\n",
    "    \n",
    "for filename in glob.glob('/Users/migmikael/Downloads/enron2/spam/*.txt'):\n",
    "    fin = open(filename, \"r\",encoding='utf-8', errors='ignore')\n",
    "    spamtexts.append(fin.read())\n",
    "    fin.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixemail = [(email, 'spam') for email in spamtexts]\n",
    "mixemail += [(email, 'ham') for email in hamtexts]\n",
    "\n",
    "random.shuffle(mixemail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(extract_features(email), label) for (email, label) in mixemail]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'upper_ratio': 0.0006293266205160479}, 'ham')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresets[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set size = 4685, test_set size = 1172\n"
     ]
    }
   ],
   "source": [
    "size = int(len(featuresets) * 0.8)\n",
    "train_set, test_set = featuresets[:size], featuresets[size:]\n",
    "print(\"train_set size = %d, test_set size = %d\" % (len(train_set), len(test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7013651877133106\n"
     ]
    }
   ],
   "source": [
    "classifier = NaiveBayesClassifier.train(train_set)\n",
    "print(classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             upper_ratio = 0.004016064257028112   spam : ham    =     26.4 : 1.0\n",
      "             upper_ratio = 0.008333333333333333   spam : ham    =     11.5 : 1.0\n",
      "             upper_ratio = 0.003067484662576687   spam : ham    =     10.2 : 1.0\n",
      "             upper_ratio = 0.000999000999000999   spam : ham    =      6.9 : 1.0\n",
      "             upper_ratio = 0.0035587188612099642   spam : ham    =      6.1 : 1.0\n",
      "             upper_ratio = 0.0024390243902439024   spam : ham    =      6.1 : 1.0\n",
      "             upper_ratio = 0.00684931506849315   spam : ham    =      6.1 : 1.0\n",
      "             upper_ratio = 0.001669449081803005   spam : ham    =      6.1 : 1.0\n",
      "             upper_ratio = 0.0016666666666666668   spam : ham    =      6.1 : 1.0\n",
      "             upper_ratio = 0.002702702702702703   spam : ham    =      4.9 : 1.0\n",
      "             upper_ratio = 0.00099601593625498   spam : ham    =      4.7 : 1.0\n",
      "             upper_ratio = 0.002824858757062147   spam : ham    =      4.7 : 1.0\n",
      "             upper_ratio = 0.001402524544179523   spam : ham    =      4.7 : 1.0\n",
      "             upper_ratio = 0.007246376811594203   spam : ham    =      4.7 : 1.0\n",
      "             upper_ratio = 0.0014064697609001407   spam : ham    =      4.7 : 1.0\n",
      "             upper_ratio = 0.004310344827586207   spam : ham    =      4.7 : 1.0\n",
      "             upper_ratio = 0.0024330900243309003   spam : ham    =      4.7 : 1.0\n",
      "             upper_ratio = 0.005681818181818182   spam : ham    =      4.7 : 1.0\n",
      "             upper_ratio = 0.0013736263736263737   spam : ham    =      4.7 : 1.0\n",
      "             upper_ratio = 0.001639344262295082   spam : ham    =      4.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85128905583063\n",
      "0.8493930197268589\n",
      "0.8497973117132495\n",
      "0.8481228668941979\n",
      "0.8413420528859824\n",
      "0.8342428376534788\n",
      "0.8146570089475926\n",
      "0.7985244040862656\n",
      "0.7757009345794392\n",
      "0.6976351351351351\n",
      "Average Accuracy :  0.816070462745283\n"
     ]
    }
   ],
   "source": [
    "num_folds = 10\n",
    "subset_size = len(featuresets) // num_folds\n",
    "accu_list = []\n",
    "for i in range(num_folds):\n",
    "    testing_this_round = featuresets[i*subset_size:]\n",
    "    training_this_round = featuresets[:i*subset_size] + featuresets[(i+1)*subset_size:]\n",
    "    \n",
    "    classifier = NaiveBayesClassifier.train(training_this_round)\n",
    "    accu = classify.accuracy(classifier, testing_this_round) \n",
    "    accu_list.append(accu)\n",
    "    print(accu)\n",
    "    \n",
    "    #print(len(testing_this_round))\n",
    "    #print(len(training_this_round))\n",
    "    #print()\n",
    "avg_accu = sum(accu_list) / len(accu_list)\n",
    "print(\"Average Accuracy : \", avg_accu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged = [mail[1] for mail in test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = [classifier.classify(mail[0]) for mail in test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ham', 'ham', 'ham', 'spam', 'ham', 'spam', 'spam', 'ham', 'ham', 'spam']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ham', 'ham', 'ham', 'spam', 'ham', 'spam', 'spam', 'ham', 'ham', 'ham']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     |       s |\n",
      "     |   h   p |\n",
      "     |   a   a |\n",
      "     |   m   m |\n",
      "-----+---------+\n",
      " ham |<748>127 |\n",
      "spam | 135<162>|\n",
      "-----+---------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.metrics import ConfusionMatrix\n",
    "cm = ConfusionMatrix(ref, tagged)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ham', 'spam'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = {'ham', 'spam'}\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 910 Counter({'ham': 748, 'spam': 162})\n",
      "FN: 262 Counter({'spam': 135, 'ham': 127})\n",
      "FP: 262 Counter({'ham': 135, 'spam': 127})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "true_positives = Counter()\n",
    "false_negatives = Counter()\n",
    "false_positives = Counter()\n",
    "\n",
    "for i in labels:\n",
    "    for j in labels:\n",
    "        if i == j:\n",
    "            true_positives[i] += cm[i,j]\n",
    "        else:\n",
    "            false_negatives[i] += cm[i,j]\n",
    "            false_positives[j] += cm[i,j]\n",
    "\n",
    "print(\"TP:\", sum(true_positives.values()), true_positives)\n",
    "print(\"FN:\", sum(false_negatives.values()), false_negatives)\n",
    "print(\"FP:\", sum(false_positives.values()), false_positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
