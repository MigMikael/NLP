{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://cambridgespark.com/content/tutorials/implementing-your-own-spam-filter/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, NaiveBayesClassifier\n",
    "from nltk import classify\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import random\n",
    "import os, glob, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamtexts = []\n",
    "spamtexts = []\n",
    "\n",
    "for filename in glob.glob('/Users/migmikael/Downloads/enron1/ham/*.txt'):\n",
    "    fin = open(filename, \"r\",encoding='utf-8', errors='ignore')\n",
    "    hamtexts.append(fin.read())\n",
    "    fin.close()\n",
    "    \n",
    "for filename in glob.glob('/Users/migmikael/Downloads/enron1/spam/*.txt'):\n",
    "    fin = open(filename, \"r\",encoding='utf-8', errors='ignore')\n",
    "    spamtexts.append(fin.read())\n",
    "    fin.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixemail = [(email, 'spam') for email in spamtexts]\n",
    "mixemail += [(email, 'ham') for email in hamtexts]\n",
    "\n",
    "random.shuffle(mixemail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlemmatizer = WordNetLemmatizer()\n",
    "commonwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    return [wordlemmatizer.lemmatize(word.lower()) for word in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(text, setting):\n",
    "    if setting=='bow':\n",
    "        return {word: count for word, count in Counter(preprocess(text)).items() if not word in commonwords}\n",
    "    else:\n",
    "        return {word: True for word in preprocess(text) if not word in commonwords}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(get_features(email, 'bow'), label) for (email, label) in mixemail]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'$': 9,\n",
       "  \"'\": 3,\n",
       "  ',': 14,\n",
       "  '-': 1,\n",
       "  '.': 13,\n",
       "  '2003': 3,\n",
       "  '210': 1,\n",
       "  '270': 1,\n",
       "  '50': 1,\n",
       "  '520': 1,\n",
       "  '580': 1,\n",
       "  '60': 2,\n",
       "  '800': 1,\n",
       "  '860': 1,\n",
       "  ':': 8,\n",
       "  '?': 1,\n",
       "  'ability': 1,\n",
       "  'able': 1,\n",
       "  'access': 1,\n",
       "  'advanced': 1,\n",
       "  'allow': 1,\n",
       "  'analyze': 1,\n",
       "  'anytime': 1,\n",
       "  'anywhere': 1,\n",
       "  'application': 2,\n",
       "  'available': 1,\n",
       "  'away': 2,\n",
       "  'bell': 1,\n",
       "  'brand': 1,\n",
       "  'build': 2,\n",
       "  'building': 1,\n",
       "  'business': 1,\n",
       "  'catalogue': 1,\n",
       "  'cd': 1,\n",
       "  'center': 1,\n",
       "  'charge': 1,\n",
       "  'click': 1,\n",
       "  'code': 1,\n",
       "  'collaboration': 1,\n",
       "  'come': 1,\n",
       "  'communication': 1,\n",
       "  'competitionsabine': 1,\n",
       "  'computing': 1,\n",
       "  'concurred': 1,\n",
       "  'connect': 1,\n",
       "  'connected': 2,\n",
       "  'context': 1,\n",
       "  'data': 1,\n",
       "  'database': 2,\n",
       "  'delivers': 1,\n",
       "  'demand': 1,\n",
       "  'deploy': 1,\n",
       "  'design': 1,\n",
       "  'designed': 1,\n",
       "  'digging': 1,\n",
       "  'dollar': 1,\n",
       "  'easy': 1,\n",
       "  'edition': 1,\n",
       "  'enhanced': 1,\n",
       "  'experience': 1,\n",
       "  'fancy': 1,\n",
       "  'feature': 3,\n",
       "  'fifty': 1,\n",
       "  'fraction': 1,\n",
       "  'get': 1,\n",
       "  'give': 1,\n",
       "  'great': 1,\n",
       "  'hannibal': 1,\n",
       "  'help': 1,\n",
       "  'home': 2,\n",
       "  'improved': 2,\n",
       "  'includes': 1,\n",
       "  'information': 2,\n",
       "  'infrastructure': 3,\n",
       "  'instead': 1,\n",
       "  'large': 1,\n",
       "  'list': 1,\n",
       "  'manage': 2,\n",
       "  'manual': 1,\n",
       "  'many': 1,\n",
       "  'menu': 1,\n",
       "  'microsoft': 3,\n",
       "  'much': 1,\n",
       "  'multiple': 1,\n",
       "  'need': 3,\n",
       "  'network': 2,\n",
       "  'new': 6,\n",
       "  'oem': 1,\n",
       "  'office': 2,\n",
       "  'officexp': 1,\n",
       "  'one': 1,\n",
       "  'option': 2,\n",
       "  'order': 3,\n",
       "  'packaging': 1,\n",
       "  'performance': 1,\n",
       "  'platform': 2,\n",
       "  'plus': 1,\n",
       "  'pop': 1,\n",
       "  'powerful': 1,\n",
       "  'powering': 1,\n",
       "  'predictor': 1,\n",
       "  'premier': 1,\n",
       "  'price': 2,\n",
       "  'privacy': 1,\n",
       "  'productive': 1,\n",
       "  'professional': 2,\n",
       "  'provides': 1,\n",
       "  'psychopath': 1,\n",
       "  'put': 1,\n",
       "  'quickly': 1,\n",
       "  'reach': 1,\n",
       "  'receive': 1,\n",
       "  'recovery': 1,\n",
       "  'registration': 1,\n",
       "  'reliability': 1,\n",
       "  'required': 1,\n",
       "  'rescind': 1,\n",
       "  'retail': 4,\n",
       "  'right': 1,\n",
       "  'save': 3,\n",
       "  'secure': 1,\n",
       "  'security': 1,\n",
       "  'sensitive': 1,\n",
       "  'server': 4,\n",
       "  'service': 1,\n",
       "  'shipping': 1,\n",
       "  'size': 1,\n",
       "  'smart': 1,\n",
       "  'software': 5,\n",
       "  'solution': 1,\n",
       "  'sql': 1,\n",
       "  'standard': 1,\n",
       "  'step': 1,\n",
       "  'subject': 1,\n",
       "  'superb': 1,\n",
       "  'tag': 1,\n",
       "  'task': 1,\n",
       "  'taskpane': 1,\n",
       "  'time': 1,\n",
       "  'title': 1,\n",
       "  'tool': 1,\n",
       "  'unique': 1,\n",
       "  'use': 1,\n",
       "  'user': 1,\n",
       "  'view': 1,\n",
       "  'visual': 1,\n",
       "  'web': 1,\n",
       "  'whistle': 1,\n",
       "  'whole': 1,\n",
       "  'wicksashay': 1,\n",
       "  'window': 5,\n",
       "  'windowsxp': 1,\n",
       "  'within': 1,\n",
       "  'without': 1,\n",
       "  'worker': 1,\n",
       "  'workgroup': 1,\n",
       "  'xp': 4,\n",
       "  '|': 6},\n",
       " 'spam')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set size = 4137, test_set size = 1035\n"
     ]
    }
   ],
   "source": [
    "size = int(len(featuresets) * 0.8)\n",
    "train_set, test_set = featuresets[:size], featuresets[size:]\n",
    "print(\"train_set size = %d, test_set size = %d\" % (len(train_set), len(test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.936231884057971\n"
     ]
    }
   ],
   "source": [
    "classifier = NaiveBayesClassifier.train(train_set)\n",
    "print(classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "               forwarded = 1                 ham : spam   =    145.4 : 1.0\n",
      "            prescription = 1                spam : ham    =     97.3 : 1.0\n",
      "                     nom = 1                 ham : spam   =     91.1 : 1.0\n",
      "                    pain = 1                spam : ham    =     81.2 : 1.0\n",
      "                   meter = 1                 ham : spam   =     72.0 : 1.0\n",
      "                    2005 = 1                spam : ham    =     70.0 : 1.0\n",
      "                    spam = 1                spam : ham    =     70.0 : 1.0\n",
      "                      ex = 1                spam : ham    =     66.8 : 1.0\n",
      "                     sex = 1                spam : ham    =     65.2 : 1.0\n",
      "                creative = 1                spam : ham    =     63.6 : 1.0\n",
      "                   cheap = 1                spam : ham    =     60.3 : 1.0\n",
      "                featured = 1                spam : ham    =     58.7 : 1.0\n",
      "            solicitation = 1                spam : ham    =     55.5 : 1.0\n",
      "               trademark = 1                spam : ham    =     55.5 : 1.0\n",
      "                congress = 1                spam : ham    =     52.3 : 1.0\n",
      "               complaint = 1                spam : ham    =     52.3 : 1.0\n",
      "                    sony = 1                spam : ham    =     52.3 : 1.0\n",
      "              pertaining = 1                spam : ham    =     49.1 : 1.0\n",
      "             legislation = 1                spam : ham    =     49.1 : 1.0\n",
      "                     971 = 2                spam : ham    =     49.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9578499613302398\n",
      "0.9583243823845328\n",
      "0.9550507491541808\n",
      "0.9541563104114885\n",
      "0.9484536082474226\n",
      "0.9516814843448009\n",
      "0.9550724637681159\n",
      "0.9568576947842885\n",
      "0.944015444015444\n",
      "0.9383429672447013\n",
      "Average Accuracy :  0.9519805065685215\n"
     ]
    }
   ],
   "source": [
    "num_folds = 10\n",
    "subset_size = len(featuresets) // num_folds\n",
    "accu_list = []\n",
    "for i in range(num_folds):\n",
    "    testing_this_round = featuresets[i*subset_size:]\n",
    "    training_this_round = featuresets[:i*subset_size] + featuresets[(i+1)*subset_size:]\n",
    "    \n",
    "    classifier = NaiveBayesClassifier.train(training_this_round)\n",
    "    accu = classify.accuracy(classifier, testing_this_round) \n",
    "    accu_list.append(accu)\n",
    "    print(accu)\n",
    "    \n",
    "    #print(len(testing_this_round))\n",
    "    #print(len(training_this_round))\n",
    "    #print()\n",
    "avg_accu = sum(accu_list) / len(accu_list)\n",
    "print(\"Average Accuracy : \", avg_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged = [mail[1] for mail in test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = [classifier.classify(mail[0]) for mail in test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     |       s |\n",
      "     |   h   p |\n",
      "     |   a   a |\n",
      "     |   m   m |\n",
      "-----+---------+\n",
      " ham |<694>  5 |\n",
      "spam |  52<284>|\n",
      "-----+---------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.metrics import ConfusionMatrix\n",
    "cm = ConfusionMatrix(ref, tagged)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ham', 'spam'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = {'ham', 'spam'}\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 978 Counter({'ham': 694, 'spam': 284})\n",
      "FN: 57 Counter({'spam': 52, 'ham': 5})\n",
      "FP: 57 Counter({'ham': 52, 'spam': 5})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "true_positives = Counter()\n",
    "false_negatives = Counter()\n",
    "false_positives = Counter()\n",
    "\n",
    "for i in labels:\n",
    "    for j in labels:\n",
    "        if i == j:\n",
    "            true_positives[i] += cm[i,j]\n",
    "        else:\n",
    "            false_negatives[i] += cm[i,j]\n",
    "            false_positives[j] += cm[i,j]\n",
    "\n",
    "print(\"TP:\", sum(true_positives.values()), true_positives)\n",
    "print(\"FN:\", sum(false_negatives.values()), false_negatives)\n",
    "print(\"FP:\", sum(false_positives.values()), false_positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
