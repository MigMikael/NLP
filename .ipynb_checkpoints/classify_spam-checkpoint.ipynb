{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, NaiveBayesClassifier\n",
    "from nltk import classify\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import random\n",
    "import os, glob, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlemmatizer = WordNetLemmatizer()\n",
    "commonwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamtexts = []\n",
    "spamtexts = []\n",
    "\n",
    "for filename in glob.glob('/Users/migmikael/Downloads/enron1/ham/*.txt'):\n",
    "    fin = open(filename, \"r\",encoding='utf-8', errors='ignore')\n",
    "    hamtexts.append(fin.read())\n",
    "    fin.close()\n",
    "    \n",
    "for filename in glob.glob('/Users/migmikael/Downloads/enron1/spam/*.txt'):\n",
    "    fin = open(filename, \"r\",encoding='utf-8', errors='ignore')\n",
    "    spamtexts.append(fin.read())\n",
    "    fin.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Subject: what up , , your cam babe\\nwhat are you looking for ?\\nif your looking for a companion for friendship , love , a date , or just good ole '\\nfashioned * * * * * * , then try our brand new site ; it was developed and created\\nto help anyone find what they ' re looking for . a quick bio form and you ' re\\non the road to satisfaction in every sense of the word . . . . no matter what\\nthat may be !\\ntry it out and youll be amazed .\\nhave a terrific time this evening\\ncopy and pa ste the add . ress you see on the line below into your browser to come to the site .\\nhttp : / / www . meganbang . biz / bld / acc /\\nno more plz\\nhttp : / / www . naturalgolden . com / retract /\\ncounterattack aitken step preemptive shoehorn scaup . electrocardiograph movie honeycomb . monster war brandywine pietism byrne catatonia . encomia lookup intervenor skeleton turn catfish .\\n\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spamtexts[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixemail = [(email, 'spam') for email in spamtexts]\n",
    "mixemail += [(email, 'ham') for email in hamtexts]\n",
    "\n",
    "random.shuffle(mixemail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(sent):\n",
    "    features = {}\n",
    "    wordtokens = [wordlemmatizer.lemmatize(word.lower()) for word in word_tokenize(sent)]\n",
    "    \n",
    "    for word in wordtokens:\n",
    "        if word not in commonwords:\n",
    "            features[word] = True\n",
    "            \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': True, 'iron': True, 'man': True}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor(\"I am iron man.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(feature_extractor(email), label) for (email, label) in mixemail]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'#': True,\n",
       "   '&': True,\n",
       "   \"'\": True,\n",
       "   ',': True,\n",
       "   '-': True,\n",
       "   '.': True,\n",
       "   '/': True,\n",
       "   '01': True,\n",
       "   '02': True,\n",
       "   '03': True,\n",
       "   '04': True,\n",
       "   '05': True,\n",
       "   '06': True,\n",
       "   '08': True,\n",
       "   '09': True,\n",
       "   '0985192': True,\n",
       "   '0986757': True,\n",
       "   '1': True,\n",
       "   '102775': True,\n",
       "   '11': True,\n",
       "   '110502': True,\n",
       "   '117848': True,\n",
       "   '12': True,\n",
       "   '14': True,\n",
       "   '17': True,\n",
       "   '18': True,\n",
       "   '1999': True,\n",
       "   '2000': True,\n",
       "   '201': True,\n",
       "   '215': True,\n",
       "   '26': True,\n",
       "   '266962': True,\n",
       "   '269123': True,\n",
       "   '30': True,\n",
       "   '31': True,\n",
       "   '4': True,\n",
       "   '45': True,\n",
       "   '5': True,\n",
       "   '5192': True,\n",
       "   '55': True,\n",
       "   '6757': True,\n",
       "   '7': True,\n",
       "   '87426': True,\n",
       "   '95072': True,\n",
       "   '99': True,\n",
       "   ':': True,\n",
       "   '?': True,\n",
       "   '@': True,\n",
       "   'able': True,\n",
       "   'accounting': True,\n",
       "   'activity': True,\n",
       "   'addition': True,\n",
       "   'aimee': True,\n",
       "   'allocated': True,\n",
       "   'also': True,\n",
       "   'april': True,\n",
       "   'arrangement': True,\n",
       "   'asap': True,\n",
       "   'asking': True,\n",
       "   'attach': True,\n",
       "   'aug': True,\n",
       "   'b': True,\n",
       "   'back': True,\n",
       "   'boa': True,\n",
       "   'bridge': True,\n",
       "   'call': True,\n",
       "   'calling': True,\n",
       "   'camp': True,\n",
       "   'cc': True,\n",
       "   'chance': True,\n",
       "   'close': True,\n",
       "   'clynes': True,\n",
       "   'conner': True,\n",
       "   'connor': True,\n",
       "   'contract': True,\n",
       "   'copy': True,\n",
       "   'corp': True,\n",
       "   'correct': True,\n",
       "   'could': True,\n",
       "   'counterparty': True,\n",
       "   'created': True,\n",
       "   'crow': True,\n",
       "   'customer': True,\n",
       "   'daren': True,\n",
       "   'day': True,\n",
       "   'deal': True,\n",
       "   'doe': True,\n",
       "   'done': True,\n",
       "   'duke': True,\n",
       "   'e': True,\n",
       "   'ect': True,\n",
       "   'email': True,\n",
       "   'ena': True,\n",
       "   'energy': True,\n",
       "   'enron': True,\n",
       "   'essentially': True,\n",
       "   'ever': True,\n",
       "   'farmer': True,\n",
       "   'find': True,\n",
       "   'fixed': True,\n",
       "   'flow': True,\n",
       "   'forwarded': True,\n",
       "   'forwarding': True,\n",
       "   'fred': True,\n",
       "   'gas': True,\n",
       "   'get': True,\n",
       "   'give': True,\n",
       "   'gomes': True,\n",
       "   'ha': True,\n",
       "   'heard': True,\n",
       "   'help': True,\n",
       "   'hey': True,\n",
       "   'hou': True,\n",
       "   'howard': True,\n",
       "   'hpl': True,\n",
       "   'id': True,\n",
       "   'invoice': True,\n",
       "   'issue': True,\n",
       "   'j': True,\n",
       "   'july': True,\n",
       "   'june': True,\n",
       "   'know': True,\n",
       "   'koch': True,\n",
       "   'lannou': True,\n",
       "   'lateral': True,\n",
       "   'let': True,\n",
       "   'like': True,\n",
       "   'lloyd': True,\n",
       "   'look': True,\n",
       "   'may': True,\n",
       "   'meter': True,\n",
       "   'mid': True,\n",
       "   'money': True,\n",
       "   'month': True,\n",
       "   'mop': True,\n",
       "   'mtr': True,\n",
       "   'need': True,\n",
       "   'never': True,\n",
       "   'new': True,\n",
       "   'next': True,\n",
       "   'nov': True,\n",
       "   'number': True,\n",
       "   'owe': True,\n",
       "   'pat': True,\n",
       "   'payback': True,\n",
       "   'please': True,\n",
       "   'pm': True,\n",
       "   'pop': True,\n",
       "   'price': True,\n",
       "   'provide': True,\n",
       "   'put': True,\n",
       "   'question': True,\n",
       "   'reallocate': True,\n",
       "   'reallocated': True,\n",
       "   'reallocates': True,\n",
       "   'record': True,\n",
       "   'redraft': True,\n",
       "   'reporting': True,\n",
       "   'resolved': True,\n",
       "   'respect': True,\n",
       "   'robert': True,\n",
       "   'sarco': True,\n",
       "   'second': True,\n",
       "   'sept': True,\n",
       "   'set': True,\n",
       "   'settlement': True,\n",
       "   'show': True,\n",
       "   'since': True,\n",
       "   'start': True,\n",
       "   'stephanie': True,\n",
       "   'still': True,\n",
       "   'stranger': True,\n",
       "   'subject': True,\n",
       "   'thanks': True,\n",
       "   'track': True,\n",
       "   'trading': True,\n",
       "   'transaction': True,\n",
       "   'transport': True,\n",
       "   'transportation': True,\n",
       "   'two': True,\n",
       "   'u': True,\n",
       "   'use': True,\n",
       "   'vacation': True,\n",
       "   'valid': True,\n",
       "   'volume': True,\n",
       "   'wait': True,\n",
       "   'week': True,\n",
       "   'would': True},\n",
       "  'ham')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresets[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set size = 4137, test_set size = 1035\n"
     ]
    }
   ],
   "source": [
    "size = int(len(featuresets) * 0.8)\n",
    "train_set, test_set = featuresets[:size], featuresets[size:]\n",
    "print(\"train_set size = %d, test_set size = %d\" % (len(train_set), len(test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.936231884057971\n"
     ]
    }
   ],
   "source": [
    "classifier = NaiveBayesClassifier.train(train_set)\n",
    "print(classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                     hou = True              ham : spam   =    189.0 : 1.0\n",
      "                   meter = True              ham : spam   =    181.8 : 1.0\n",
      "                    2004 = True             spam : ham    =    159.5 : 1.0\n",
      "                     nom = True              ham : spam   =    127.2 : 1.0\n",
      "                    pain = True             spam : ham    =     99.6 : 1.0\n",
      "                    2005 = True             spam : ham    =     86.6 : 1.0\n",
      "                  dealer = True             spam : ham    =     83.4 : 1.0\n",
      "                featured = True             spam : ham    =     80.2 : 1.0\n",
      "              medication = True             spam : ham    =     76.9 : 1.0\n",
      "                  differ = True             spam : ham    =     76.9 : 1.0\n",
      "                    2001 = True              ham : spam   =     73.7 : 1.0\n",
      "                creative = True             spam : ham    =     68.8 : 1.0\n",
      "                     ibm = True             spam : ham    =     67.2 : 1.0\n",
      "                  weight = True             spam : ham    =     65.6 : 1.0\n",
      "                     ect = True              ham : spam   =     65.1 : 1.0\n",
      "                     713 = True              ham : spam   =     64.4 : 1.0\n",
      "                   adobe = True             spam : ham    =     64.0 : 1.0\n",
      "               clearance = True             spam : ham    =     62.3 : 1.0\n",
      "                inherent = True             spam : ham    =     60.7 : 1.0\n",
      "                congress = True             spam : ham    =     60.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9671179883945842\n",
      "0.9535783365570599\n",
      "0.9381044487427466\n",
      "0.9477756286266924\n",
      "0.9477756286266924\n",
      "0.9381044487427466\n",
      "0.9361702127659575\n",
      "0.9555125725338491\n",
      "0.941972920696325\n",
      "0.9303675048355899\n",
      "Average Accuracy :  0.9456479690522244\n"
     ]
    }
   ],
   "source": [
    "num_folds = 10\n",
    "subset_size = len(featuresets) // num_folds\n",
    "accu_list = []\n",
    "for i in range(num_folds):\n",
    "    testing_this_round = featuresets[i*subset_size:][:subset_size]\n",
    "    training_this_round = featuresets[:i*subset_size] + featuresets[(i+1)*subset_size:]\n",
    "    \n",
    "    classifier = NaiveBayesClassifier.train(training_this_round)\n",
    "    accu = classify.accuracy(classifier, testing_this_round) \n",
    "    accu_list.append(accu)\n",
    "    print(accu)\n",
    "    \n",
    "    #print(len(testing_this_round))\n",
    "    #print(len(training_this_round))\n",
    "    #print()\n",
    "avg_accu = sum(accu_list) / len(accu_list)\n",
    "print(\"Average Accuracy : \", avg_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
