{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Import แพคเกจที่จำเป็น"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, NaiveBayesClassifier, DecisionTreeClassifier, MaxentClassifier\n",
    "from nltk import classify\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "wordlemmatizer = WordNetLemmatizer()\n",
    "stopword_list = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish Read Data 100000 Record\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "count = 0\n",
    "\n",
    "with open('twitter.csv', \"r\",encoding='utf-8', errors='ignore') as data_file:\n",
    "    for line in data_file:\n",
    "        count += 1\n",
    "        if count == 1:\n",
    "            continue\n",
    "        first_comma = line.index(\",\")\n",
    "        second_comma = line.index(\",\", first_comma+1)\n",
    "        front = line[:second_comma]\n",
    "        rear = line[second_comma+1:]\n",
    "        \n",
    "        no, sentiment = front.split(\",\")\n",
    "        sentiment = \"pos\" if sentiment == \"1\" else \"neg\"\n",
    "        data.append((sentiment, rear))\n",
    "        \n",
    "print(\"Finish Read Data\",len(data), \"Record\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('pos', '@cupcake_kayla haha yes you do ')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[99999]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Pre Precess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## แกะ Feature วิธีที่ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True\n",
    "def feature_extractor_1(sent):\n",
    "    features = {}\n",
    "    wordtokens = [wordlemmatizer.lemmatize(word.lower()) for word in word_tokenize(sent)]\n",
    "    \n",
    "    for word in wordtokens:\n",
    "        if word not in stopword_list:\n",
    "            features[word] = True\n",
    "            \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': True, 'iron': True, 'man': True}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor_1(\"I am the iron man.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## แกะ Feature วิธีที่ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count\n",
    "def preprocess(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    return [wordlemmatizer.lemmatize(word.lower()) for word in tokens]\n",
    "\n",
    "def feature_extractor_2(text):\n",
    "    return {word: count for word, count in Counter(preprocess(text)).items() if not word in stopword_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 1, 'iron': 1, 'man': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor_2(\"I am the iron man.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Divide Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio 5 combination 0.5, 0.6, 0.7, 0.8, 0.9 \n",
    "def divide_featureset(ratio, featuresets):\n",
    "    size = int(len(featuresets) * ratio)\n",
    "    train_set, test_set = featuresets[:size], featuresets[size:]\n",
    "    #print(\"train_set size = %d, test_set size = %d\" % (len(train_set), len(test_set)))\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets_1 = [(feature_extractor_1(text), sentiment) for (sentiment, text) in data]\n",
    "featuresets_2 = [(feature_extractor_2(text), sentiment) for (sentiment, text) in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True 0.5 NaiveBayes\n",
      "True 0.5 NaiveBayes 0.7329\n",
      "True 0.6 NaiveBayes\n",
      "True 0.6 NaiveBayes 0.73435\n",
      "True 0.7 NaiveBayes\n",
      "True 0.7 NaiveBayes 0.7359333333333333\n",
      "True 0.8 NaiveBayes\n",
      "True 0.8 NaiveBayes 0.7358\n",
      "True 0.9 NaiveBayes\n",
      "True 0.9 NaiveBayes 0.7306\n",
      "Count 0.5 NaiveBayes\n",
      "Count 0.5 NaiveBayes 0.73184\n",
      "Count 0.6 NaiveBayes\n",
      "Count 0.6 NaiveBayes 0.7318\n",
      "Count 0.7 NaiveBayes\n",
      "Count 0.7 NaiveBayes 0.7353333333333333\n",
      "Count 0.8 NaiveBayes\n",
      "Count 0.8 NaiveBayes 0.73485\n",
      "Count 0.9 NaiveBayes\n",
      "Count 0.9 NaiveBayes 0.7316\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "feature_list = ['True', 'Count']\n",
    "pre_precess_list = [1, 2, 3]\n",
    "ratio_list = [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "#training_algo_list = ['NaiveBayes', 'DecisionTree', 'Maxent']\n",
    "training_algo_list = ['NaiveBayes']\n",
    "\n",
    "classifier_dict = {}\n",
    "for feature in feature_list:\n",
    "    for ratio in ratio_list:\n",
    "        for algo in training_algo_list:\n",
    "            print(feature, ratio, algo)\n",
    "            \n",
    "            if feature == 'True':\n",
    "                featureset = featuresets_1\n",
    "            else:\n",
    "                featureset = featuresets_2\n",
    "                \n",
    "            train_set, test_set = divide_featureset(ratio, featureset)\n",
    "            \n",
    "            if algo == 'NaiveBayes':\n",
    "                classifier = NaiveBayesClassifier.train(train_set)\n",
    "            elif algo == 'DecisionTree':\n",
    "                classifier = DecisionTreeClassifier.train(train_set, binary=True)\n",
    "            elif algo == 'Maxent':\n",
    "                classifier = MaxentClassifier.train(train_set, trace=0)\n",
    "            else:\n",
    "                classifier = None\n",
    "            \n",
    "            accu = classify.accuracy(classifier, test_set)\n",
    "            classifier_dict[feature + ' ' + str(ratio) + ' ' + algo] = (classifier, accu)\n",
    "            print(feature + ' ' + str(ratio) + ' ' + algo, accu)\n",
    "            \n",
    "#print(classifier_dict)\n",
    "#current_classifier = classifier_dict['True 0.5 NaiveBayes']\n",
    "print(len(classifier_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = int(len(featuresets_1) * 0.8)\n",
    "train_set_1, test_set_1 = featuresets[:size], featuresets[size:]\n",
    "print(\"train_set size = %d, test_set size = %d\" % (len(train_set_1), len(test_set_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_classifier = NaiveBayesClassifier.train(train_set_1)\n",
    "print(classify.accuracy(naive_classifier, test_set_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_classifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
